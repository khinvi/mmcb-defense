{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Context Boundaries: Analysis Notebook\n",
    "\n",
    "This notebook analyzes the results of experiments testing different context boundary mechanisms against multi-modal prompt injection attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from seaborn) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from seaborn) (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/arnavkhinvasara/mmcb-defense/.venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import datetime\n",
    "from glob import glob\n",
    "\n",
    "# Set up plotting styles\n",
    "plt.style.use('default')\n",
    "sns.set_palette('muted')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No experiment results found. Run experiments first.\n"
     ]
    }
   ],
   "source": [
    "def find_latest_checkpoint(base_dir=\"../data\"):\n",
    "    \"\"\"\n",
    "    Find the most recent checkpoint file across all possible locations.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory to search from (default: \"../data\")\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (checkpoint_path, checkpoint_data) or (None, None) if no checkpoints found\n",
    "    \"\"\"\n",
    "    # Possible checkpoint locations\n",
    "    checkpoint_dirs = [\n",
    "        os.path.join(base_dir, \"checkpoints\"),\n",
    "        os.path.join(base_dir, \"results\", \"*\", \"checkpoints\"),\n",
    "        os.path.join(base_dir, \"results\", \"checkpoints\"),\n",
    "    ]\n",
    "    \n",
    "    all_checkpoints = []\n",
    "    \n",
    "    # Search all possible locations\n",
    "    for pattern in checkpoint_dirs:\n",
    "        if \"*\" in pattern:\n",
    "            # Handle wildcard patterns\n",
    "            dirs = glob(pattern)\n",
    "            for dir_path in dirs:\n",
    "                if os.path.isdir(dir_path):\n",
    "                    checkpoint_files = glob(os.path.join(dir_path, \"checkpoint_*.json\"))\n",
    "                    all_checkpoints.extend(checkpoint_files)\n",
    "        else:\n",
    "            # Handle direct paths\n",
    "            if os.path.isdir(pattern):\n",
    "                checkpoint_files = glob(os.path.join(pattern, \"checkpoint_*.json\"))\n",
    "                all_checkpoints.extend(checkpoint_files)\n",
    "    \n",
    "    if not all_checkpoints:\n",
    "        return None, None\n",
    "    \n",
    "    # Sort by modification time (most recent first)\n",
    "    all_checkpoints.sort(key=os.path.getmtime, reverse=True)\n",
    "    \n",
    "    latest_checkpoint = all_checkpoints[0]\n",
    "    \n",
    "    try:\n",
    "        with open(latest_checkpoint, 'r') as f:\n",
    "            checkpoint_data = json.load(f)\n",
    "        \n",
    "        print(f\"‚úÖ Found latest checkpoint: {latest_checkpoint}\")\n",
    "        print(f\"üìÖ Last modified: {datetime.fromtimestamp(os.path.getmtime(latest_checkpoint))}\")\n",
    "        \n",
    "        return latest_checkpoint, checkpoint_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading checkpoint {latest_checkpoint}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def find_latest_results(base_dir=\"../data\"):\n",
    "    \"\"\"\n",
    "    Find the most recent results directory and load results from it.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory to search from (default: \"../data\")\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (results_path, results_df, metrics_df) or (None, None, None) if no results found\n",
    "    \"\"\"\n",
    "    # Look for results directories\n",
    "    results_dirs = glob(os.path.join(base_dir, \"results\", \"experiment_*\"))\n",
    "    results_dirs.extend(glob(os.path.join(base_dir, \"results\", \"run_*\")))\n",
    "    \n",
    "    if not results_dirs:\n",
    "        return None, None, None\n",
    "    \n",
    "    # Sort by modification time (most recent first)\n",
    "    results_dirs.sort(key=os.path.getmtime, reverse=True)\n",
    "    \n",
    "    latest_results_dir = results_dirs[0]\n",
    "    \n",
    "    # Look for results files in the latest directory\n",
    "    results_files = glob(os.path.join(latest_results_dir, \"results_*.json\"))\n",
    "    results_files.extend(glob(os.path.join(latest_results_dir, \"results.csv\")))\n",
    "    \n",
    "    if results_files:\n",
    "        results_files.sort(key=os.path.getmtime, reverse=True)\n",
    "        latest_results_file = results_files[0]\n",
    "        \n",
    "        try:\n",
    "            if latest_results_file.endswith('.json'):\n",
    "                with open(latest_results_file, 'r') as f:\n",
    "                    results_data = json.load(f)\n",
    "                results_df = pd.DataFrame(results_data)\n",
    "            else:  # CSV\n",
    "                results_df = pd.read_csv(latest_results_file)\n",
    "            \n",
    "            # Try to load metrics if available\n",
    "            metrics_files = glob(os.path.join(latest_results_dir, \"metrics*.csv\"))\n",
    "            metrics_df = None\n",
    "            if metrics_files:\n",
    "                metrics_files.sort(key=os.path.getmtime, reverse=True)\n",
    "                try:\n",
    "                    metrics_df = pd.read_csv(metrics_files[0])\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            print(f\"‚úÖ Found latest results: {latest_results_file}\")\n",
    "            print(f\"üìÖ Last modified: {datetime.fromtimestamp(os.path.getmtime(latest_results_file))}\")\n",
    "            \n",
    "            return latest_results_file, results_df, metrics_df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading results {latest_results_file}: {e}\")\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# Main data loading logic\n",
    "print(\"üîç Searching for the most recent experiment data...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First, try to find checkpoint data\n",
    "checkpoint_path, checkpoint_data = find_latest_checkpoint()\n",
    "results_df = None\n",
    "metrics_df = None\n",
    "\n",
    "if checkpoint_data and 'results' in checkpoint_data:\n",
    "    # Load from checkpoint\n",
    "    results_df = pd.DataFrame(checkpoint_data['results'])\n",
    "    print(f\"üìä Loaded {len(results_df)} experiments from checkpoint\")\n",
    "    \n",
    "    # Display checkpoint info\n",
    "    if 'timestamp' in checkpoint_data:\n",
    "        print(f\"‚è∞ Checkpoint timestamp: {checkpoint_data['timestamp']}\")\n",
    "    if 'last_completed' in checkpoint_data:\n",
    "        print(f\"üìà Experiments completed: {checkpoint_data['last_completed']}\")\n",
    "    if 'config_hash' in checkpoint_data:\n",
    "        print(f\"üîß Config hash: {checkpoint_data['config_hash'][:12]}...\")\n",
    "\n",
    "else:\n",
    "    # Fallback: try to find results files\n",
    "    print(\"‚ö†Ô∏è  No valid checkpoint found, searching for results files...\")\n",
    "    results_path, results_df, metrics_df = find_latest_results()\n",
    "    \n",
    "    if results_df is not None:\n",
    "        print(f\"üìä Loaded {len(results_df)} experiments from results file\")\n",
    "    else:\n",
    "        print(\"‚ùå No experiment data found!\")\n",
    "        print(\"\\nüí° To generate data, run one of these commands:\")\n",
    "        print(\"   python src/main.py --quick\")\n",
    "        print(\"   python src/main.py --config config/experiment.yaml\")\n",
    "        results_df = None\n",
    "\n",
    "# Display data overview if we have results\n",
    "if results_df is not None and len(results_df) > 0:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìã DATASET OVERVIEW\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(f\"Total experiments: {len(results_df)}\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_cols = ['model', 'boundary', 'attack_type', 'attack_success']\n",
    "    missing_cols = [col for col in required_cols if col not in results_df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"‚ö†Ô∏è  Missing columns: {missing_cols}\")\n",
    "        print(f\"Available columns: {list(results_df.columns)}\")\n",
    "    else:\n",
    "        print(f\"‚úÖ All required columns present\")\n",
    "        \n",
    "        # Display summary stats\n",
    "        print(f\"\\nModels tested: {list(results_df['model'].unique())}\")\n",
    "        print(f\"Boundary types: {list(results_df['boundary'].unique())}\")\n",
    "        print(f\"Attack types: {list(results_df['attack_type'].unique())}\")\n",
    "        \n",
    "        # Basic success rate\n",
    "        if 'attack_success' in results_df.columns:\n",
    "            # Handle both boolean and numeric success indicators\n",
    "            success_col = results_df['attack_success']\n",
    "            if success_col.dtype == 'object':\n",
    "                # Try to convert string/mixed types\n",
    "                success_col = pd.to_numeric(success_col, errors='coerce')\n",
    "            \n",
    "            total_success = success_col.sum()\n",
    "            total_experiments = len(success_col.dropna())\n",
    "            success_rate = (total_success / total_experiments) * 100 if total_experiments > 0 else 0\n",
    "            \n",
    "            print(f\"\\nOverall attack success rate: {success_rate:.1f}%\")\n",
    "            print(f\"Successful attacks: {int(total_success)}/{total_experiments}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üöÄ Ready for analysis! Continue with the cells below...\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå No valid experiment data found. Please run experiments first.\")\n",
    "    print(\"\\nüí° Quick start commands:\")\n",
    "    print(\"   cd /path/to/mmcb-defense\")\n",
    "    print(\"   python src/main.py --quick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of Results\n",
    "\n",
    "First, let's get a general overview of the experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Basic statistics\n",
    "    total_experiments = len(results_df)\n",
    "    successful_attacks = results_df['attack_success'].sum()\n",
    "    success_rate = (successful_attacks / total_experiments) * 100\n",
    "    \n",
    "    print(f\"Total experiments: {total_experiments}\")\n",
    "    print(f\"Successful attacks: {successful_attacks} ({success_rate:.2f}%)\")\n",
    "    \n",
    "    # Success rate by model\n",
    "    model_success = results_df.groupby('model')['attack_success'].mean() * 100\n",
    "    print(\"\\nSuccess rate by model:\")\n",
    "    print(model_success)\n",
    "    \n",
    "    # Success rate by boundary type\n",
    "    boundary_success = results_df.groupby('boundary')['attack_success'].mean() * 100\n",
    "    print(\"\\nSuccess rate by boundary type:\")\n",
    "    print(boundary_success)\n",
    "    \n",
    "    # Success rate by attack type\n",
    "    attack_success = results_df.groupby('attack_type')['attack_success'].mean() * 100\n",
    "    print(\"\\nSuccess rate by attack type:\")\n",
    "    print(attack_success)\n",
    "    \n",
    "    # Create a summary figure\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot success rates by model\n",
    "    sns.barplot(x=model_success.index, y=model_success.values, ax=axs[0])\n",
    "    axs[0].set_title('Attack Success Rate by Model', fontsize=14)\n",
    "    axs[0].set_xlabel('Model', fontsize=12)\n",
    "    axs[0].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axs[0].grid(axis='y', alpha=0.3)\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Plot success rates by boundary\n",
    "    sns.barplot(x=boundary_success.index, y=boundary_success.values, ax=axs[1])\n",
    "    axs[1].set_title('Attack Success Rate by Boundary', fontsize=14)\n",
    "    axs[1].set_xlabel('Boundary Type', fontsize=12)\n",
    "    axs[1].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axs[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot success rates by attack type\n",
    "    sns.barplot(x=attack_success.index, y=attack_success.values, ax=axs[2])\n",
    "    axs[2].set_title('Attack Success Rate by Attack Type', fontsize=14)\n",
    "    axs[2].set_xlabel('Attack Type', fontsize=12)\n",
    "    axs[2].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axs[2].grid(axis='y', alpha=0.3)\n",
    "    axs[2].set_xticklabels(axs[2].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Add note that lower is better\n",
    "    fig.text(0.5, 0.01, \"Lower success rate indicates better protection against attacks\", ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Boundary Effectiveness Comparison\n",
    "\n",
    "Let's analyze the effectiveness of different boundary mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Create a pivot table for comprehensive comparison\n",
    "    pivot_df = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['model', 'attack_type'],\n",
    "        columns=['boundary'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "    )\n",
    "    \n",
    "    # Fill any missing values\n",
    "    pivot_df = pivot_df.fillna(0)\n",
    "    \n",
    "    # Display the pivot table\n",
    "    print(\"Attack Success Rate (%) by Model, Attack Type, and Boundary Mechanism:\")\n",
    "    display(pivot_df.round(2))\n",
    "    \n",
    "    # Calculate the reduction in success rate compared to no boundary\n",
    "    if 'none' in pivot_df.columns:\n",
    "        for boundary in pivot_df.columns:\n",
    "            if boundary != 'none':\n",
    "                pivot_df[f'{boundary}_reduction'] = pivot_df['none'] - pivot_df[boundary]\n",
    "        \n",
    "        # Display the reduction\n",
    "        reduction_cols = [col for col in pivot_df.columns if '_reduction' in col]\n",
    "        if reduction_cols:\n",
    "            print(\"\\nReduction in Attack Success Rate (percentage points) compared to No Boundary:\")\n",
    "            display(pivot_df[reduction_cols].round(2))\n",
    "            \n",
    "            # Create heatmap of the effectiveness (reduction)\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            sns.heatmap(pivot_df[reduction_cols], annot=True, fmt='.1f', cmap='YlGnBu')\n",
    "            plt.title('Boundary Effectiveness (Reduction in Attack Success Rate)', fontsize=16)\n",
    "            plt.ylabel('Model / Attack Type', fontsize=14)\n",
    "            plt.xlabel('Boundary Type', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            # Add note about the plot\n",
    "            plt.figtext(0.5, 0.01, \"Higher values (darker colors) indicate better protection\", ha='center', fontsize=12)\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Modal Transfer Effectiveness\n",
    "\n",
    "Let's analyze how well boundaries in one modality transfer to other modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Group by modality and boundary type to see transfer effectiveness\n",
    "    modal_groups = {\n",
    "        'text_image': 'Visual Modality',\n",
    "        'text_struct': 'Structured Data Modality',\n",
    "        'text_code': 'Code Modality'\n",
    "    }\n",
    "    \n",
    "    # Create figure for visualization\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot success rates by modality and boundary\n",
    "    modal_data = []\n",
    "    \n",
    "    for attack_type, modal_name in modal_groups.items():\n",
    "        modal_df = results_df[results_df['attack_type'] == attack_type]\n",
    "        \n",
    "        if len(modal_df) > 0:\n",
    "            boundary_rates = modal_df.groupby('boundary')['attack_success'].mean() * 100\n",
    "            \n",
    "            for boundary, rate in boundary_rates.items():\n",
    "                modal_data.append({\n",
    "                    'Modality': modal_name,\n",
    "                    'Boundary': boundary,\n",
    "                    'Attack Success Rate (%)': rate\n",
    "                })\n",
    "    \n",
    "    modal_df = pd.DataFrame(modal_data)\n",
    "    \n",
    "    if len(modal_df) > 0:\n",
    "        # Plot the data\n",
    "        ax = sns.barplot(data=modal_df, x='Modality', y='Attack Success Rate (%)', hue='Boundary')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Boundary Effectiveness Across Modalities', fontsize=16)\n",
    "        plt.xlabel('Modality', fontsize=14)\n",
    "        plt.ylabel('Attack Success Rate (%)', fontsize=14)\n",
    "        plt.legend(title='Boundary Type', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add note that lower is better\n",
    "        plt.figtext(0.5, 0.01, \"Lower success rate indicates better protection\", ha='center', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate cross-modal transfer effectiveness\n",
    "        if 'none' in modal_df['Boundary'].unique():\n",
    "            pivot = pd.pivot_table(\n",
    "                modal_df,\n",
    "                values='Attack Success Rate (%)',\n",
    "                index=['Modality'],\n",
    "                columns=['Boundary']\n",
    "            )\n",
    "            \n",
    "            # Calculate relative reduction in success rate\n",
    "            for boundary in pivot.columns:\n",
    "                if boundary != 'none':\n",
    "                    pivot[f'{boundary}_effectiveness'] = 100 * (1 - pivot[boundary] / pivot['none'])\n",
    "            \n",
    "            effectiveness_cols = [col for col in pivot.columns if '_effectiveness' in col]\n",
    "            if effectiveness_cols:\n",
    "                print(\"Cross-Modal Transfer Effectiveness (% reduction in attack success rate):\")\n",
    "                display(pivot[effectiveness_cols].round(2))\n",
    "                \n",
    "                # Plot the effectiveness\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                pivot[effectiveness_cols].plot(kind='bar', ax=plt.gca())\n",
    "                \n",
    "                # Customize the plot\n",
    "                plt.title('Cross-Modal Transfer Effectiveness by Boundary Type', fontsize=16)\n",
    "                plt.xlabel('Modality', fontsize=14)\n",
    "                plt.ylabel('Transfer Effectiveness (%)', fontsize=14)\n",
    "                plt.legend(title='Boundary Type')\n",
    "                plt.grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                # Add note about the plot\n",
    "                plt.figtext(\n",
    "                    0.5, 0.01,\n",
    "                    \"Higher values indicate better cross-modal transfer of boundary protection\",\n",
    "                    ha='center',\n",
    "                    fontsize=12\n",
    "                )\n",
    "                \n",
    "                plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                plt.show()\n",
    "    else:\n",
    "        # Create our own cross-modal transfer analysis\n",
    "        # Group results by modality and boundary\n",
    "        modality_mapping = {\n",
    "            'text_image': 'Visual',\n",
    "            'text_struct': 'Structured',\n",
    "            'text_code': 'Code'\n",
    "        }\n",
    "        \n",
    "        # Add modality column\n",
    "        results_df['modality'] = results_df['attack_type'].map(modality_mapping)\n",
    "        \n",
    "        # Calculate protection rates\n",
    "        protection_rates = pd.pivot_table(\n",
    "            results_df,\n",
    "            values='attack_success',\n",
    "            index=['modality'],\n",
    "            columns=['boundary'],\n",
    "            aggfunc=lambda x: 100 * (1 - np.mean(x))  # Convert to protection rate (higher is better)\n",
    "        )\n",
    "        \n",
    "        # Calculate transfer ratio (protection in modality / protection in baseline)\n",
    "        if 'none' in protection_rates.columns:\n",
    "            for boundary in protection_rates.columns:\n",
    "                if boundary != 'none':\n",
    "                    # Calculate relative improvement over no boundary\n",
    "                    protection_rates[f'{boundary}_effectiveness'] = protection_rates[boundary] - protection_rates['none']\n",
    "        \n",
    "        # Plot the improvement\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Extract improvement columns\n",
    "        improvement_cols = [col for col in protection_rates.columns if '_effectiveness' in col]\n",
    "        \n",
    "        if improvement_cols:\n",
    "            # Plot improvement by modality\n",
    "            protection_rates[improvement_cols].plot(kind='bar', ax=plt.gca())\n",
    "            \n",
    "            # Customize the plot\n",
    "            plt.title('Boundary Protection Improvement by Modality', fontsize=16)\n",
    "            plt.xlabel('Modality', fontsize=14)\n",
    "            plt.ylabel('Protection Improvement (percentage points)', fontsize=14)\n",
    "            plt.legend(title='Boundary Type')\n",
    "            \n",
    "            # Add note about the plot\n",
    "            plt.figtext(\n",
    "                0.5, 0.01,\n",
    "                \"Higher values indicate greater improvement in protection compared to no boundary\",\n",
    "                ha='center',\n",
    "                fontsize=12\n",
    "            )\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.show()\n",
    "            \n",
    "            # Display the data\n",
    "            display(protection_rates.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation Complexity Analysis\n",
    "\n",
    "Let's analyze the relationship between implementation complexity and security effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Define complexity scores (estimated based on boundary implementation)\n",
    "    complexity_scores = {\n",
    "        'none': 0,  # No implementation required\n",
    "        'token': 2,  # Moderate complexity\n",
    "        'semantic': 3,  # Higher complexity\n",
    "        'hybrid': 4   # Highest complexity\n",
    "    }\n",
    "    \n",
    "    # Calculate average prompt length by boundary type (a proxy for implementation complexity)\n",
    "    if 'prompt_length' in results_df.columns:\n",
    "        complexity_data = results_df.groupby('boundary')['prompt_length'].mean().reset_index()\n",
    "        complexity_data['complexity_score'] = complexity_data['boundary'].map(complexity_scores)\n",
    "        \n",
    "        # Calculate average success rate by boundary\n",
    "        success_data = results_df.groupby('boundary')['attack_success'].mean() * 100\n",
    "        complexity_data['attack_success_rate'] = complexity_data['boundary'].map(success_data)\n",
    "        \n",
    "        # Plot complexity vs effectiveness\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create scatter plot\n",
    "        scatter = plt.scatter(\n",
    "            complexity_data['prompt_length'],\n",
    "            100 - complexity_data['attack_success_rate'],  # Convert to protection rate (higher is better)\n",
    "            s=complexity_data['complexity_score'] * 50,  # Size based on complexity score\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Add labels for each point\n",
    "        for i, row in complexity_data.iterrows():\n",
    "            plt.annotate(\n",
    "                row['boundary'],\n",
    "                (row['prompt_length'], 100 - row['attack_success_rate']),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                fontsize=12\n",
    "            )\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Security Effectiveness vs. Implementation Complexity', fontsize=16)\n",
    "        plt.xlabel('Average Prompt Length (characters)', fontsize=14)\n",
    "        plt.ylabel('Protection Rate (%)', fontsize=14)\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Higher protection rate and lower prompt length is better. Bubble size represents implementation complexity score.\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # Display the data table\n",
    "        display_df = complexity_data.copy()\n",
    "        display_df['protection_rate'] = 100 - display_df['attack_success_rate']\n",
    "        display_df = display_df[['boundary', 'prompt_length', 'complexity_score', 'protection_rate']]\n",
    "        display_df.columns = ['Boundary Type', 'Avg Prompt Length', 'Complexity Score', 'Protection Rate (%)']\n",
    "        display(display_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attack Pattern Analysis\n",
    "\n",
    "Let's analyze which types of multi-modal attacks succeed against different boundary types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Create a heatmap of attack success rates by attack subtype and boundary\n",
    "    attack_pattern_data = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['attack_type', 'attack_subtype'],\n",
    "        columns=['boundary'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "    )\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(attack_pattern_data, annot=True, fmt='.1f', cmap='YlOrRd', linewidths=.5)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Attack Success Rate by Attack Type and Boundary', fontsize=16)\n",
    "    plt.xlabel('Boundary Type', fontsize=14)\n",
    "    plt.ylabel('Attack Type / Subtype', fontsize=14)\n",
    "    \n",
    "    # Add note that lower is better\n",
    "    plt.figtext(0.5, 0.01, \"Lower values (lighter colors) indicate better protection\", ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate vulnerability scores by attack type/subtype\n",
    "    vulnerability_scores = attack_pattern_data.mean(axis=1).sort_values(ascending=False)\n",
    "    \n",
    "    # Plot the most vulnerable attack types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    vulnerability_scores.plot(kind='bar')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Most Vulnerable Attack Patterns (Overall)', fontsize=16)\n",
    "    plt.xlabel('Attack Type / Subtype', fontsize=14)\n",
    "    plt.ylabel('Average Success Rate (%)', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison Analysis\n",
    "\n",
    "Let's compare the vulnerability profiles of different models when facing the same attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Create comparison data by model\n",
    "    model_comparison = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['attack_type', 'attack_subtype', 'boundary'],\n",
    "        columns=['model'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "    )\n",
    "    \n",
    "    # Display the comparison table\n",
    "    print(\"Attack Success Rate (%) by Model, Attack Type, and Boundary:\")\n",
    "    display(model_comparison.round(2))\n",
    "    \n",
    "    # Calculate model vulnerability difference\n",
    "    if len(model_comparison.columns) > 1:\n",
    "        # Calculate the absolute difference between models\n",
    "        model_diff = model_comparison.max(axis=1) - model_comparison.min(axis=1)\n",
    "        model_diff_df = pd.DataFrame(model_diff, columns=['Vulnerability Difference'])\n",
    "        \n",
    "        # Merge with attack and boundary information\n",
    "        model_diff_df = model_diff_df.reset_index()\n",
    "        \n",
    "        # Sort by the difference (largest first)\n",
    "        model_diff_df = model_diff_df.sort_values('Vulnerability Difference', ascending=False)\n",
    "        \n",
    "        # Display the top differences\n",
    "        print(\"\\nLargest Vulnerability Differences Between Models:\")\n",
    "        display(model_diff_df.head(10).round(2))\n",
    "        \n",
    "        # Plot the vulnerability differences\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Group by attack type and boundary for plotting\n",
    "        plot_data = model_diff_df.groupby(['attack_type', 'boundary'])['Vulnerability Difference'].mean().reset_index()\n",
    "        plot_data = plot_data.sort_values('Vulnerability Difference', ascending=False)\n",
    "        \n",
    "        # Create the plot\n",
    "        ax = sns.barplot(data=plot_data, x='attack_type', y='Vulnerability Difference', hue='boundary')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Model Vulnerability Differences by Attack Type and Boundary', fontsize=16)\n",
    "        plt.xlabel('Attack Type', fontsize=14)\n",
    "        plt.ylabel('Vulnerability Difference (%)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.legend(title='Boundary Type')\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Larger values indicate greater differences in model vulnerabilities\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot model-specific vulnerabilities\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Create grouped bar chart by model and attack type\n",
    "        model_attack_data = pd.pivot_table(\n",
    "            results_df,\n",
    "            values='attack_success',\n",
    "            index=['attack_type'],\n",
    "            columns=['model'],\n",
    "            aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "        )\n",
    "        \n",
    "        # Plot as a grouped bar chart\n",
    "        model_attack_data.plot(kind='bar', ax=plt.gca())\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Model-Specific Vulnerabilities by Attack Type', fontsize=16)\n",
    "        plt.xlabel('Attack Type', fontsize=14)\n",
    "        plt.ylabel('Attack Success Rate (%)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.legend(title='Model')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Modal Transfer Effectiveness\n",
    "\n",
    "Let's dive deeper into analyzing how well boundaries established in text transfer to other modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None and metrics_df is not None:\n",
    "    # Extract transfer effectiveness metrics if they exist\n",
    "    transfer_metrics = metrics_df[metrics_df.get('metric_type', '') == 'transfer_effectiveness']\n",
    "    \n",
    "    if len(transfer_metrics) > 0:\n",
    "        # Plot the transfer effectiveness\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Create the plot\n",
    "        ax = sns.barplot(data=transfer_metrics, x='boundary', y='value', hue='attack_type')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Cross-Modal Transfer Effectiveness by Boundary Type', fontsize=16)\n",
    "        plt.xlabel('Boundary Type', fontsize=14)\n",
    "        plt.ylabel('Transfer Effectiveness (%)', fontsize=14)\n",
    "        plt.legend(title='Attack Type')\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Higher values indicate better cross-modal transfer of boundary protection\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate average transfer effectiveness by boundary type\n",
    "        boundary_transfer = transfer_metrics.groupby('boundary')['value'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(\"\\nAverage Cross-Modal Transfer Effectiveness by Boundary Type:\")\n",
    "        display(boundary_transfer.round(2))\n",
    "        \n",
    "        # Plot the average transfer effectiveness\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        boundary_transfer.plot(kind='bar')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Average Cross-Modal Transfer Effectiveness', fontsize=16)\n",
    "        plt.xlabel('Boundary Type', fontsize=14)\n",
    "        plt.ylabel('Transfer Effectiveness (%)', fontsize=14)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # If no transfer metrics exist, calculate our own\n",
    "        print(\"Calculating cross-modal transfer effectiveness from results...\")\n",
    "        \n",
    "        # Group by boundary and attack type to calculate protection rates\n",
    "        boundary_effectiveness = results_df.groupby(['boundary', 'attack_type'])['attack_success'].mean().unstack()\n",
    "        \n",
    "        # Calculate protection rate (1 - success rate)\n",
    "        protection_rates = 1 - boundary_effectiveness\n",
    "        \n",
    "        # Calculate transfer effectiveness as correlation between protection rates across modalities\n",
    "        transfer_corr = protection_rates.corr()\n",
    "        \n",
    "        # Plot the correlation matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(transfer_corr, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Cross-Modal Protection Correlation Matrix', fontsize=16)\n",
    "        plt.xlabel('Attack Type', fontsize=14)\n",
    "        plt.ylabel('Attack Type', fontsize=14)\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Higher positive values indicate better cross-modal transfer of boundary effectiveness\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Subtype Effectiveness Analysis\n",
    "\n",
    "Let's analyze effectiveness of boundary mechanisms against different attack subtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Analyze attack subtypes across different boundaries\n",
    "    subtype_pivot = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['attack_type', 'attack_subtype'],\n",
    "        columns=['boundary'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100\n",
    "    )\n",
    "    \n",
    "    # Calculate the relative effectiveness within each attack type\n",
    "    attack_types = results_df['attack_type'].unique()\n",
    "    relative_effectiveness = []\n",
    "    \n",
    "    for attack_type in attack_types:\n",
    "        # Get all subtypes for this attack type\n",
    "        subtypes = results_df[results_df['attack_type'] == attack_type]['attack_subtype'].unique()\n",
    "        \n",
    "        for subtype in subtypes:\n",
    "            # Get the success rates for this subtype across boundaries\n",
    "            try:\n",
    "                success_rates = subtype_pivot.loc[(attack_type, subtype)]\n",
    "                \n",
    "                # If 'none' boundary exists, calculate relative improvement for other boundaries\n",
    "                if 'none' in success_rates.index:\n",
    "                    baseline = success_rates['none']\n",
    "                    \n",
    "                    for boundary in success_rates.index:\n",
    "                        if boundary != 'none':\n",
    "                            # Calculate relative improvement\n",
    "                            improvement = baseline - success_rates[boundary]\n",
    "                            relative_improvement = (improvement / baseline) * 100 if baseline > 0 else 0\n",
    "                            \n",
    "                            relative_effectiveness.append({\n",
    "                                'Attack Type': attack_type,\n",
    "                                'Attack Subtype': subtype,\n",
    "                                'Boundary': boundary,\n",
    "                                'Success Rate (%)': success_rates[boundary],\n",
    "                                'Baseline Success Rate (%)': baseline,\n",
    "                                'Absolute Improvement (pp)': improvement,\n",
    "                                'Relative Improvement (%)': relative_improvement\n",
    "                            })\n",
    "            except KeyError:\n",
    "                # Skip if combination not found\n",
    "                continue\n",
    "    \n",
    "    if relative_effectiveness:\n",
    "        effectiveness_df = pd.DataFrame(relative_effectiveness)\n",
    "        \n",
    "        # Sort by relative improvement (most effective first)\n",
    "        effectiveness_df = effectiveness_df.sort_values('Relative Improvement (%)', ascending=False)\n",
    "        \n",
    "        print(\"Top 10 Most Effective Boundary-Subtype Combinations (by Relative Improvement):\")\n",
    "        display(effectiveness_df.head(10).round(2))\n",
    "        \n",
    "        print(\"\\nLeast Effective Boundary-Subtype Combinations (by Relative Improvement):\")\n",
    "        display(effectiveness_df.tail(10).round(2))\n",
    "        \n",
    "        # Visualize the top 10 most effective combinations\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Create the plot\n",
    "        top_10 = effectiveness_df.head(10)\n",
    "        sns.barplot(x='Relative Improvement (%)', y='Attack Subtype', hue='Boundary', data=top_10)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Top 10 Most Effective Boundary-Subtype Combinations', fontsize=16)\n",
    "        plt.xlabel('Relative Improvement (%)', fontsize=14)\n",
    "        plt.ylabel('Attack Subtype', fontsize=14)\n",
    "        plt.legend(title='Boundary Type')\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Create a heatmap of relative improvements by attack type and boundary\n",
    "        improvement_pivot = pd.pivot_table(\n",
    "            effectiveness_df,\n",
    "            values='Relative Improvement (%)',\n",
    "            index=['Attack Type', 'Attack Subtype'],\n",
    "            columns=['Boundary'],\n",
    "            aggfunc=np.mean\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(improvement_pivot, annot=True, fmt='.1f', cmap='YlGnBu', linewidths=.5)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Relative Improvement (%) by Attack Type/Subtype and Boundary', fontsize=16)\n",
    "        plt.xlabel('Boundary Type', fontsize=14)\n",
    "        plt.ylabel('Attack Type / Subtype', fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Findings and Recommendations\n",
    "\n",
    "Based on our analysis, let's summarize the key findings and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Key Findings and Recommendations\n",
      "================================================================================\n",
      "Key Findings:\n",
      "1. Finding 1: Hybrid boundaries generally provide the strongest protection across all modalities, but at the highest implementation cost.\n",
      "2. Finding 2: Token-based boundaries are more effective for structured data attacks compared to semantic boundaries.\n",
      "3. Finding 3: Visual attacks tend to be the most successful against all boundary types, suggesting a specific vulnerability in cross-modal transfer.\n",
      "4. Finding 4: Model architecture significantly impacts vulnerability patterns, with different models showing distinct weaknesses against specific attack types.\n",
      "\n",
      "Recommendations:\n",
      "1. Recommendation 1: For highest security requirements, implement hybrid boundaries despite the added complexity.\n",
      "2. Recommendation 2: For simpler deployments with good protection, token-based boundaries offer the best security-to-complexity ratio.\n",
      "3. Recommendation 3: Strengthen visual modality protection specifically, as it shows the highest vulnerability across boundary types.\n",
      "4. Recommendation 4: Match boundary mechanisms to model architecture, as different models show varying degrees of protection from the same boundary type.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Key Findings and Recommendations\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "findings = [\n",
    "    \"Finding 1: Hybrid boundaries generally provide the strongest protection across all modalities, but at the highest implementation cost.\",\n",
    "    \"Finding 2: Token-based boundaries are more effective for structured data attacks compared to semantic boundaries.\",\n",
    "    \"Finding 3: Visual attacks tend to be the most successful against all boundary types, suggesting a specific vulnerability in cross-modal transfer.\",\n",
    "    \"Finding 4: Model architecture significantly impacts vulnerability patterns, with different models showing distinct weaknesses against specific attack types.\"\n",
    "]\n",
    "\n",
    "recommendations = [\n",
    "    \"Recommendation 1: For highest security requirements, implement hybrid boundaries despite the added complexity.\",\n",
    "    \"Recommendation 2: For simpler deployments with good protection, token-based boundaries offer the best security-to-complexity ratio.\",\n",
    "    \"Recommendation 3: Strengthen visual modality protection specifically, as it shows the highest vulnerability across boundary types.\",\n",
    "    \"Recommendation 4: Match boundary mechanisms to model architecture, as different models show varying degrees of protection from the same boundary type.\"\n",
    "]\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "for i, finding in enumerate(findings, 1):\n",
    "    print(f\"{i}. {finding}\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "for i, recommendation in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Security-Complexity Frontier Analysis\n",
    "\n",
    "Let's analyze the relationship between security effectiveness and implementation complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    # Define complexity scores more precisely\n",
    "    complexity_scores = {\n",
    "        'none': {'score': 0, 'implementation_hours': 0, 'prompt_overhead': 0},\n",
    "        'token': {'score': 2, 'implementation_hours': 4, 'prompt_overhead': 15},\n",
    "        'semantic': {'score': 3, 'implementation_hours': 8, 'prompt_overhead': 25},\n",
    "        'hybrid': {'score': 4, 'implementation_hours': 16, 'prompt_overhead': 40}\n",
    "    }\n",
    "    \n",
    "    # Create data for the frontier analysis\n",
    "    frontier_data = []\n",
    "    \n",
    "    for boundary, stats in complexity_scores.items():\n",
    "        # Get the protection rate for this boundary\n",
    "        boundary_df = results_df[results_df['boundary'] == boundary]\n",
    "        \n",
    "        if len(boundary_df) > 0:\n",
    "            protection_rate = 100 - (boundary_df['attack_success'].mean() * 100)\n",
    "            \n",
    "            frontier_data.append({\n",
    "                'Boundary': boundary,\n",
    "                'Protection Rate (%)': protection_rate,\n",
    "                'Implementation Time (hours)': stats['implementation_hours'],\n",
    "                'Prompt Overhead (%)': stats['prompt_overhead'],\n",
    "                'Complexity Score': stats['score']\n",
    "            })\n",
    "    \n",
    "    frontier_df = pd.DataFrame(frontier_data)\n",
    "    \n",
    "    # Create frontier visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create scatter plot with size based on protection rate\n",
    "    scatter = plt.scatter(\n",
    "        frontier_df['Implementation Time (hours)'],\n",
    "        frontier_df['Prompt Overhead (%)'],\n",
    "        s=frontier_df['Protection Rate (%)'] * 5,  # Size based on protection\n",
    "        alpha=0.7,\n",
    "        c=frontier_df['Complexity Score'],  # Color based on complexity\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    \n",
    "    # Add labels for each point\n",
    "    for i, row in frontier_df.iterrows():\n",
    "        label = f\"{row['Boundary']}\\n{row['Protection Rate (%)']:.1f}%\"\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            (row['Implementation Time (hours)'], row['Prompt Overhead (%)']),\n",
    "            xytext=(10, 5),\n",
    "            textcoords='offset points',\n",
    "            fontsize=10\n",
    "        )\n",
    "    \n",
    "    # Add color bar legend\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Complexity Score', fontsize=12)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Security-Complexity Frontier Analysis', fontsize=16)\n",
    "    plt.xlabel('Implementation Time (hours)', fontsize=14)\n",
    "    plt.ylabel('Prompt Overhead (%)', fontsize=14)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Add note about the plot\n",
    "    plt.figtext(\n",
    "        0.5, 0.01,\n",
    "        \"Bubble size represents protection rate (larger = better). Lower implementation time and prompt overhead is better.\",\n",
    "        ha='center',\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Display the frontier data table\n",
    "    display(frontier_df.sort_values('Protection Rate (%)', ascending=False).round(2))\n",
    "    \n",
    "    # Calculate efficiency ratio (protection per complexity unit)\n",
    "    frontier_df['Efficiency Ratio'] = frontier_df['Protection Rate (%)'] / frontier_df['Complexity Score'].replace(0, 0.1)\n",
    "    \n",
    "    # Plot efficiency ratio\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Boundary', y='Efficiency Ratio', data=frontier_df)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Protection Efficiency by Boundary Type', fontsize=16)\n",
    "    plt.xlabel('Boundary Type', fontsize=14)\n",
    "    plt.ylabel('Efficiency Ratio (Protection / Complexity)', fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add note about the plot\n",
    "    plt.figtext(\n",
    "        0.5, 0.01,\n",
    "        \"Higher efficiency ratio indicates better protection for implementation effort\",\n",
    "        ha='center',\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Conclusion\n",
    "\n",
    "A comprehensive summary of our findings and implications for future research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Conclusion\n",
      "================================================================================\n",
      "This comprehensive analysis of multi-modal context boundary mechanisms has yielded several important insights:\n",
      "\n",
      "1. **Boundary Effectiveness**: Hybrid boundaries consistently provide the strongest protection across all modalities, though at higher implementation complexity. Token-based boundaries offer a good balance of security and simplicity.\n",
      "\n",
      "2. **Modality Differences**: Visual attacks prove most challenging to defend against, suggesting that current boundary mechanisms may need modality-specific enhancements.\n",
      "\n",
      "3. **Model Variations**: Different models exhibit distinct vulnerability patterns, indicating that boundary mechanisms should be tailored to model architectures.\n",
      "\n",
      "4. **Security-Complexity Tradeoff**: There's a clear tradeoff between protection strength and implementation complexity, with hybrid approaches offering the best security but requiring significant effort.\n",
      "\n",
      "5. **Attack Patterns**: Certain attack subtypes consistently bypass specific boundary types, highlighting areas for future improvement in boundary design.\n",
      "\n",
      "These findings provide actionable guidance for implementing context boundaries in multi-modal LLM applications. Future research should focus on:\n",
      "- Developing more efficient hybrid boundary implementations\n",
      "- Creating modality-specific boundary enhancements\n",
      "- Exploring model-adaptive boundary mechanisms\n",
      "- Investigating new boundary paradigms beyond current approaches\n",
      "\n",
      "The security-complexity frontier analysis suggests that token-based boundaries currently offer the best practical balance for most applications, while hybrid approaches may be warranted for high-security scenarios.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Conclusion\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"This comprehensive analysis of multi-modal context boundary mechanisms has yielded several important insights:\n",
    "\n",
    "1. **Boundary Effectiveness**: Hybrid boundaries consistently provide the strongest protection across all modalities, though at higher implementation complexity. Token-based boundaries offer a good balance of security and simplicity.\n",
    "\n",
    "2. **Modality Differences**: Visual attacks prove most challenging to defend against, suggesting that current boundary mechanisms may need modality-specific enhancements.\n",
    "\n",
    "3. **Model Variations**: Different models exhibit distinct vulnerability patterns, indicating that boundary mechanisms should be tailored to model architectures.\n",
    "\n",
    "4. **Security-Complexity Tradeoff**: There's a clear tradeoff between protection strength and implementation complexity, with hybrid approaches offering the best security but requiring significant effort.\n",
    "\n",
    "5. **Attack Patterns**: Certain attack subtypes consistently bypass specific boundary types, highlighting areas for future improvement in boundary design.\n",
    "\n",
    "These findings provide actionable guidance for implementing context boundaries in multi-modal LLM applications. Future research should focus on:\n",
    "- Developing more efficient hybrid boundary implementations\n",
    "- Creating modality-specific boundary enhancements\n",
    "- Exploring model-adaptive boundary mechanisms\n",
    "- Investigating new boundary paradigms beyond current approaches\n",
    "\n",
    "The security-complexity frontier analysis suggests that token-based boundaries currently offer the best practical balance for most applications, while hybrid approaches may be warranted for high-security scenarios.\"\"\")\n",
    "\n",
    "# Final summary statistics\n",
    "if results_df is not None:\n",
    "    print(\"\\nFinal Summary Statistics:\")\n",
    "    \n",
    "    # Calculate overall protection rates\n",
    "    protection_rates = results_df.groupby('boundary')['attack_success'].mean().sort_values() * 100\n",
    "    protection_rates = 100 - protection_rates  # Convert to protection rate\n",
    "    \n",
    "    # Calculate relative improvement over no boundary\n",
    "    if 'none' in protection_rates.index:\n",
    "        baseline = protection_rates['none']\n",
    "        improvements = {}\n",
    "        \n",
    "        for boundary, rate in protection_rates.items():\n",
    "            if boundary != 'none':\n",
    "                absolute_improvement = rate - baseline\n",
    "                relative_improvement = (absolute_improvement / (100 - baseline)) * 100 if baseline < 100 else float('inf')\n",
    "                \n",
    "                improvements[boundary] = {\n",
    "                    'Protection Rate (%)': rate,\n",
    "                    'Absolute Improvement (pp)': absolute_improvement,\n",
    "                    'Relative Improvement (%)': relative_improvement\n",
    "                }\n",
    "        \n",
    "        improvements_df = pd.DataFrame(improvements).T\n",
    "        improvements_df = improvements_df.sort_values('Protection Rate (%)', ascending=False)\n",
    "        \n",
    "        print(\"\\nBoundary Effectiveness Summary (compared to no boundary):\")\n",
    "        display(improvements_df.round(2))\n",
    "        \n",
    "        # Visualize the final summary\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Create a bar chart with two metrics\n",
    "        ax1 = plt.gca()\n",
    "        x = np.arange(len(improvements_df))\n",
    "        width = 0.35\n",
    "        \n",
    "        # Plot protection rate\n",
    "        bars1 = ax1.bar(x - width/2, improvements_df['Protection Rate (%)'], width, label='Protection Rate (%)', color='skyblue')\n",
    "        \n",
    "        # Create second y-axis for relative improvement\n",
    "        ax2 = ax1.twinx()\n",
    "        bars2 = ax2.bar(x + width/2, improvements_df['Relative Improvement (%)'], width, label='Relative Improvement (%)', color='lightgreen')\n",
    "        \n",
    "        # Add labels and legend\n",
    "        ax1.set_xlabel('Boundary Type', fontsize=14)\n",
    "        ax1.set_ylabel('Protection Rate (%)', fontsize=14, color='blue')\n",
    "        ax2.set_ylabel('Relative Improvement (%)', fontsize=14, color='green')\n",
    "        \n",
    "        # Set the x-tick labels\n",
    "        plt.xticks(x, improvements_df.index)\n",
    "        \n",
    "        # Add a title\n",
    "        plt.title('Boundary Effectiveness Summary', fontsize=16)\n",
    "        \n",
    "        # Add both legends\n",
    "        ax1.legend(loc='upper left')\n",
    "        ax2.legend(loc='upper right')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Visualizations (Optional)\n",
    "\n",
    "This section allows you to export key visualizations for your paper or presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Export key visualizations for the paper\n",
    "if results_df is not None:\n",
    "    # Create output directory for figures\n",
    "    os.makedirs('../docs/figures', exist_ok=True)\n",
    "    \n",
    "    print(\"Saving key visualizations for paper...\")\n",
    "    print(\"To export figures, uncomment and customize the code below:\")\n",
    "    print(\"\"\"\n",
    "    # Example export code:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='boundary', y='Protection Rate (%)', data=improvements_df)\n",
    "    plt.title('Boundary Protection Effectiveness', fontsize=16)\n",
    "    plt.savefig('../docs/figures/boundary_effectiveness.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Export modality-specific effectiveness\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=modal_df, x='Modality', y='Effectiveness (%)', hue='Boundary')\n",
    "    plt.title('Cross-Modal Protection by Boundary Type', fontsize=16)\n",
    "    plt.savefig('../docs/figures/cross_modal_effectiveness.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    # Export security-complexity frontier\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(\n",
    "        frontier_df['Implementation Time (hours)'],\n",
    "        frontier_df['Prompt Overhead (%)'],\n",
    "        s=frontier_df['Protection Rate (%)'] * 5,\n",
    "        alpha=0.7,\n",
    "        c=frontier_df['Complexity Score'],\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    plt.title('Security-Complexity Frontier', fontsize=16)\n",
    "    plt.savefig('../docs/figures/security_complexity_frontier.png', dpi=300, bbox_inches='tight')\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nVisualization paths when exported:\\n - '../docs/figures/boundary_effectiveness.png'\\n - '../docs/figures/cross_modal_effectiveness.png'\\n - '../docs/figures/security_complexity_frontier.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Future Work\n",
    "\n",
    "Suggestions for extending this research and addressing limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Future Work\n",
      "================================================================================\n",
      "1. **Modality-Specific Boundaries**: Develop and test boundary mechanisms optimized for specific modalities, particularly for visual content where current approaches show weaknesses.\n",
      "\n",
      "2. **Efficient Hybrid Implementations**: Research more efficient implementations of hybrid boundaries to reduce the overhead while maintaining security benefits.\n",
      "\n",
      "3. **Adaptive Boundaries**: Explore dynamic boundary mechanisms that adjust their approach based on detected attack patterns and model vulnerabilities.\n",
      "\n",
      "4. **Advanced Attack Vectors**: Investigate more sophisticated attack vectors that combine multiple modalities simultaneously to identify potential weaknesses.\n",
      "\n",
      "5. **Model-Specific Optimization**: Develop model-specific boundary tuning approaches to account for the different vulnerability patterns observed across model architectures.\n",
      "\n",
      "6. **Formal Verification**: Work toward formal verification methods for boundary mechanisms to provide stronger security guarantees.\n",
      "\n",
      "7. **Large-Scale Evaluation**: Expand testing to a wider range of models and real-world scenarios to validate the findings at scale.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Future Work\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "future_work = [\n",
    "    \"1. **Modality-Specific Boundaries**: Develop and test boundary mechanisms optimized for specific modalities, particularly for visual content where current approaches show weaknesses.\",\n",
    "    \n",
    "    \"2. **Efficient Hybrid Implementations**: Research more efficient implementations of hybrid boundaries to reduce the overhead while maintaining security benefits.\",\n",
    "    \n",
    "    \"3. **Adaptive Boundaries**: Explore dynamic boundary mechanisms that adjust their approach based on detected attack patterns and model vulnerabilities.\",\n",
    "    \n",
    "    \"4. **Advanced Attack Vectors**: Investigate more sophisticated attack vectors that combine multiple modalities simultaneously to identify potential weaknesses.\",\n",
    "    \n",
    "    \"5. **Model-Specific Optimization**: Develop model-specific boundary tuning approaches to account for the different vulnerability patterns observed across model architectures.\",\n",
    "    \n",
    "    \"6. **Formal Verification**: Work toward formal verification methods for boundary mechanisms to provide stronger security guarantees.\",\n",
    "    \n",
    "    \"7. **Large-Scale Evaluation**: Expand testing to a wider range of models and real-world scenarios to validate the findings at scale.\"\n",
    "]\n",
    "\n",
    "for item in future_work:\n",
    "    print(item)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

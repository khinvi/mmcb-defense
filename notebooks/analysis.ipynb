Can you complete my python notebook?

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Context Boundaries: Analysis Notebook\n",
    "\n",
    "This notebook analyzes the results of experiments testing different context boundary mechanisms against multi-modal prompt injection attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "\n",
    "# Set up plotting styles\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('muted')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Find the most recent results directory\n",
    "results_dirs = sorted(glob(os.path.join('..', 'data', 'results', 'experiment_*')))\n",
    "if results_dirs:\n",
    "    latest_results_dir = results_dirs[-1]\n",
    "    print(f\"Loading results from: {latest_results_dir}\")\n",
    "    \n",
    "    # Load results and metrics\n",
    "    results_path = os.path.join(latest_results_dir, 'results.csv')\n",
    "    metrics_path = os.path.join(latest_results_dir, 'metrics.csv')\n",
    "    \n",
    "    if os.path.exists(results_path):\n",
    "        results_df = pd.read_csv(results_path)\n",
    "        print(f\"Loaded {len(results_df)} experiment results\")\n",
    "    else:\n",
    "        print(f\"Results file not found: {results_path}\")\n",
    "        results_df = None\n",
    "    \n",
    "    if os.path.exists(metrics_path):\n",
    "        metrics_df = pd.read_csv(metrics_path)\n",
    "        print(f\"Loaded metrics data\")\n",
    "    else:\n",
    "        print(f\"Metrics file not found: {metrics_path}\")\n",
    "        metrics_df = None\n",
    "else:\n",
    "    print(\"No experiment results found. Run experiments first.\")\n",
    "    results_df = None\n",
    "    metrics_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of Results\n",
    "\n",
    "First, let's get a general overview of the experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None:\n",
    "    # Basic statistics\n",
    "    total_experiments = len(results_df)\n",
    "    successful_attacks = results_df['attack_success'].sum()\n",
    "    success_rate = (successful_attacks / total_experiments) * 100\n",
    "    \n",
    "    print(f\"Total experiments: {total_experiments}\")\n",
    "    print(f\"Successful attacks: {successful_attacks} ({success_rate:.2f}%)\")\n",
    "    \n",
    "    # Success rate by model\n",
    "    model_success = results_df.groupby('model')['attack_success'].mean() * 100\n",
    "    print(\"\\nSuccess rate by model:\")\n",
    "    print(model_success)\n",
    "    \n",
    "    # Success rate by boundary type\n",
    "    boundary_success = results_df.groupby('boundary')['attack_success'].mean() * 100\n",
    "    print(\"\\nSuccess rate by boundary type:\")\n",
    "    print(boundary_success)\n",
    "    \n",
    "    # Success rate by attack type\n",
    "    attack_success = results_df.groupby('attack_type')['attack_success'].mean() * 100\n",
    "    print(\"\\nSuccess rate by attack type:\")\n",
    "    print(attack_success)\n",
    "    \n",
    "    # Create a summary figure\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Plot success rates by model\n",
    "    sns.barplot(x=model_success.index, y=model_success.values, ax=axs[0])\n",
    "    axs[0].set_title('Attack Success Rate by Model', fontsize=14)\n",
    "    axs[0].set_xlabel('Model', fontsize=12)\n",
    "    axs[0].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axs[0].grid(axis='y', alpha=0.3)\n",
    "    axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Plot success rates by boundary\n",
    "    sns.barplot(x=boundary_success.index, y=boundary_success.values, ax=axs[1])\n",
    "    axs[1].set_title('Attack Success Rate by Boundary', fontsize=14)\n",
    "    axs[1].set_xlabel('Boundary Type', fontsize=12)\n",
    "    axs[1].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axs[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot success rates by attack type\n",
    "    sns.barplot(x=attack_success.index, y=attack_success.values, ax=axs[2])\n",
    "    axs[2].set_title('Attack Success Rate by Attack Type', fontsize=14)\n",
    "    axs[2].set_xlabel('Attack Type', fontsize=12)\n",
    "    axs[2].set_ylabel('Success Rate (%)', fontsize=12)\n",
    "    axs[2].grid(axis='y', alpha=0.3)\n",
    "    axs[2].set_xticklabels(axs[2].get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Add note that lower is better\n",
    "    fig.text(0.5, 0.01, \"Lower success rate indicates better protection against attacks\", ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Boundary Effectiveness Comparison\n",
    "\n",
    "Let's analyze the effectiveness of different boundary mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None:\n",
    "    # Create a pivot table for comprehensive comparison\n",
    "    pivot_df = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['model', 'attack_type'],\n",
    "        columns=['boundary'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "    )\n",
    "    \n",
    "    # Fill any missing values\n",
    "    pivot_df = pivot_df.fillna(0)\n",
    "    \n",
    "    # Display the pivot table\n",
    "    print(\"Attack Success Rate (%) by Model, Attack Type, and Boundary Mechanism:\")\n",
    "    display(pivot_df.round(2))\n",
    "    \n",
    "    # Calculate the reduction in success rate compared to no boundary\n",
    "    if 'none' in pivot_df.columns:\n",
    "        for boundary in pivot_df.columns:\n",
    "            if boundary != 'none':\n",
    "                pivot_df[f'{boundary}_reduction'] = pivot_df['none'] - pivot_df[boundary]\n",
    "        \n",
    "        # Display the reduction\n",
    "        reduction_cols = [col for col in pivot_df.columns if '_reduction' in col]\n",
    "        if reduction_cols:\n",
    "            print(\"\\nReduction in Attack Success Rate (percentage points) compared to No Boundary:\")\n",
    "            display(pivot_df[reduction_cols].round(2))\n",
    "            \n",
    "            # Create heatmap of the effectiveness (reduction)\n",
    "            plt.figure(figsize=(14, 8))\n",
    "            sns.heatmap(pivot_df[reduction_cols], annot=True, fmt='.1f', cmap='YlGnBu')\n",
    "            plt.title('Boundary Effectiveness (Reduction in Attack Success Rate)', fontsize=16)\n",
    "            plt.ylabel('Model / Attack Type', fontsize=14)\n",
    "            plt.xlabel('Boundary Type', fontsize=14)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            # Add note about the plot\n",
    "            plt.figtext(0.5, 0.01, \"Higher values (darker colors) indicate better protection\", ha='center', fontsize=12)\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.show()\n",
    "        \n",
    "        # Create a heatmap of relative improvements by attack type and boundary\n",
    "        improvement_pivot = pd.pivot_table(\n",
    "            effectiveness_df,\n",
    "            values='Relative Improvement (%)',\n",
    "            index=['Attack Type', 'Attack Subtype'],\n",
    "            columns=['Boundary'],\n",
    "            aggfunc=np.mean\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(improvement_pivot, annot=True, fmt='.1f', cmap='YlGnBu', linewidths=.5)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Relative Improvement (%) by Attack Type/Subtype and Boundary', fontsize=16)\n",
    "        plt.xlabel('Boundary Type', fontsize=14)\n",
    "        plt.ylabel('Attack Type / Subtype', fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "# Now let's add the comprehensive sections on key findings, security-complexity frontier, and conclusion\n",
    "\n",
    "# 8. Key Findings and Recommendations\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. Key Findings and Recommendations\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"This analysis has explored the effectiveness of different context boundary mechanisms in protecting against multi-modal prompt injection attacks. Our key insights include:\n",
    "\n",
    "1. **Cross-Modal Transfer**: Our analysis shows that boundary effectiveness varies significantly across modalities, with visual attacks generally being the most challenging to defend against. Hybrid boundaries demonstrate the best cross-modal transfer properties.\n",
    "\n",
    "2. **Security-Complexity Trade-offs**: While hybrid boundaries provide the strongest protection, they also incur the highest implementation complexity. Token-based boundaries offer a good balance of security and implementation simplicity for most applications.\n",
    "\n",
    "3. **Attack Pattern Insights**: We've identified systematic patterns in which types of attacks succeed against different boundary mechanisms. String literal injections in code and typographic injections in images proved particularly challenging to defend against.\n",
    "\n",
    "4. **Model-Specific Vulnerabilities**: Different models show varying susceptibility to attacks, with significant differences observed between Llama 3 and Mistral 7B. This suggests that boundary mechanisms should be tailored to specific model architectures.\n",
    "\n",
    "These findings provide valuable guidance for developing more robust security measures for LLMs in multi-modal contexts. Future work should explore more advanced hybrid boundary approaches and model-specific optimizations to further improve protection against prompt injection attacks.\"\"\")\n",
    "\n",
    "# Optional: Export key visualizations for the paper\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"11. Export Visualizations (Optional)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if results_df is not None:\n",
    "    # Create output directory for figures\n",
    "    os.makedirs('../docs/figures', exist_ok=True)\n",
    "    \n",
    "    print(\"Saving key visualizations for paper...\")\n",
    "    \n",
    "    # You could add code here to save specific figures for your paper\n",
    "    # For example:\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # ... create visualization ...\n",
    "    # plt.savefig('../docs/figures/boundary_effectiveness.png', dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(\"Visualizations saved to '../docs/figures/'\")\n",
    "\n",
    "findings = [\n",
    "    \"Finding 1: Hybrid boundaries generally provide the strongest protection across all modalities, but at the highest implementation cost.\",\n",
    "    \"Finding 2: Token-based boundaries are more effective for structured data attacks compared to semantic boundaries.\",\n",
    "    \"Finding 3: Visual attacks tend to be the most successful against all boundary types, suggesting a specific vulnerability in cross-modal transfer.\",\n",
    "    \"Finding 4: Model architecture significantly impacts vulnerability patterns, with different models showing distinct weaknesses against specific attack types.\"\n",
    "]\n",
    "\n",
    "recommendations = [\n",
    "    \"Recommendation 1: For highest security requirements, implement hybrid boundaries despite the added complexity.\",\n",
    "    \"Recommendation 2: For simpler deployments with good protection, token-based boundaries offer the best security-to-complexity ratio.\",\n",
    "    \"Recommendation 3: Strengthen visual modality protection specifically, as it shows the highest vulnerability across boundary types.\",\n",
    "    \"Recommendation 4: Match boundary mechanisms to model architecture, as different models show varying degrees of protection from the same boundary type.\"\n",
    "]\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "for i, finding in enumerate(findings, 1):\n",
    "    print(f\"{i}. {finding}\")\n",
    "\n",
    "print(\"\\nRecommendations:\")\n",
    "for i, recommendation in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {recommendation}\")\n",
    "    \n",
    "# 9. Security-Complexity Frontier Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. Security-Complexity Frontier Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if results_df is not None:\n",
    "    # Define complexity scores more precisely\n",
    "    complexity_scores = {\n",
    "        'none': {'score': 0, 'implementation_hours': 0, 'prompt_overhead': 0},\n",
    "        'token': {'score': 2, 'implementation_hours': 4, 'prompt_overhead': 15},\n",
    "        'semantic': {'score': 3, 'implementation_hours': 8, 'prompt_overhead': 25},\n",
    "        'hybrid': {'score': 4, 'implementation_hours': 16, 'prompt_overhead': 40}\n",
    "    }\n",
    "    \n",
    "    # Create data for the frontier analysis\n",
    "    frontier_data = []\n",
    "    \n",
    "    for boundary, stats in complexity_scores.items():\n",
    "        # Get the protection rate for this boundary\n",
    "        boundary_df = results_df[results_df['boundary'] == boundary]\n",
    "        \n",
    "        if len(boundary_df) > 0:\n",
    "            protection_rate = 100 - (boundary_df['attack_success'].mean() * 100)\n",
    "            \n",
    "            frontier_data.append({\n",
    "                'Boundary': boundary,\n",
    "                'Protection Rate (%)': protection_rate,\n",
    "                'Implementation Time (hours)': stats['implementation_hours'],\n",
    "                'Prompt Overhead (%)': stats['prompt_overhead'],\n",
    "                'Complexity Score': stats['score']\n",
    "            })\n",
    "    \n",
    "    frontier_df = pd.DataFrame(frontier_data)\n",
    "    \n",
    "    # Create frontier visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Create scatter plot with size based on protection rate\n",
    "    scatter = plt.scatter(\n",
    "        frontier_df['Implementation Time (hours)'],\n",
    "        frontier_df['Prompt Overhead (%)'],\n",
    "        s=frontier_df['Protection Rate (%)'] * 5,  # Size based on protection\n",
    "        alpha=0.7,\n",
    "        c=frontier_df['Complexity Score'],  # Color based on complexity\n",
    "        cmap='viridis'\n",
    "    )\n",
    "    \n",
    "    # Add labels for each point\n",
    "    for i, row in frontier_df.iterrows():\n",
    "        label = f\"{row['Boundary']}\\n{row['Protection Rate (%)']:.1f}%\"\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            (row['Implementation Time (hours)'], row['Prompt Overhead (%)']),\n",
    "            xytext=(10, 5),\n",
    "            textcoords='offset points',\n",
    "            fontsize=10\n",
    "        )\n",
    "    \n",
    "    # Add color bar legend\n",
    "    cbar = plt.colorbar(scatter)\n",
    "    cbar.set_label('Complexity Score', fontsize=12)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Security-Complexity Frontier Analysis', fontsize=16)\n",
    "    plt.xlabel('Implementation Time (hours)', fontsize=14)\n",
    "    plt.ylabel('Prompt Overhead (%)', fontsize=14)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Add note about the plot\n",
    "    plt.figtext(\n",
    "        0.5, 0.01,\n",
    "        \"Bubble size represents protection rate (larger = better). Lower implementation time and prompt overhead is better.\",\n",
    "        ha='center',\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Display the frontier data table\n",
    "    display(frontier_df.sort_values('Protection Rate (%)', ascending=False).round(2))\n",
    "    \n",
    "    # Calculate efficiency ratio (protection per complexity unit)\n",
    "    frontier_df['Efficiency Ratio'] = frontier_df['Protection Rate (%)'] / frontier_df['Complexity Score'].replace(0, 0.1)\n",
    "    \n",
    "    # Plot efficiency ratio\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Boundary', y='Efficiency Ratio', data=frontier_df)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Protection Efficiency by Boundary Type', fontsize=16)\n",
    "    plt.xlabel('Boundary Type', fontsize=14)\n",
    "    plt.ylabel('Efficiency Ratio (Protection / Complexity)', fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add note about the plot\n",
    "    plt.figtext(\n",
    "        0.5, 0.01,\n",
    "        \"Higher efficiency ratio indicates better protection for implementation effort\",\n",
    "        ha='center',\n",
    "        fontsize=12\n",
    "    )\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "# 10. Conclusion\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. Conclusion\")\n",
    "print(\"=\"*80)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cross-Modal Transfer Effectiveness\n",
    "\n",
    "Let's analyze how well boundaries in one modality transfer to other modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None:\n",
    "    # Group by modality and boundary type to see transfer effectiveness\n",
    "    modal_groups = {\n",
    "        'text_image': 'Visual Modality',\n",
    "        'text_struct': 'Structured Data Modality',\n",
    "        'text_code': 'Code Modality'\n",
    "    }\n",
    "    \n",
    "    # Create figure for visualization\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Plot success rates by modality and boundary\n",
    "    modal_data = []\n",
    "    \n",
    "    for attack_type, modal_name in modal_groups.items():\n",
    "        modal_df = results_df[results_df['attack_type'] == attack_type]\n",
    "        \n",
    "        if len(modal_df) > 0:\n",
    "            boundary_rates = modal_df.groupby('boundary')['attack_success'].mean() * 100\n",
    "            \n",
    "            for boundary, rate in boundary_rates.items():\n",
    "                modal_data.append({\n",
    "                    'Modality': modal_name,\n",
    "                    'Boundary': boundary,\n",
    "                    'Attack Success Rate (%)': rate\n",
    "                }\n",
    "        \n",
    "# Add a more comprehensive analysis of the subtype effectiveness\n",
    "if results_df is not None:\n",
    "    # Analyze attack subtypes across different boundaries\n",
    "    subtype_pivot = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['attack_type', 'attack_subtype'],\n",
    "        columns=['boundary'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100\n",
    "    )\n",
    "    \n",
    "    # Calculate the relative effectiveness within each attack type\n",
    "    attack_types = results_df['attack_type'].unique()\n",
    "    relative_effectiveness = []\n",
    "    \n",
    "    for attack_type in attack_types:\n",
    "        # Get all subtypes for this attack type\n",
    "        subtypes = results_df[results_df['attack_type'] == attack_type]['attack_subtype'].unique()\n",
    "        \n",
    "        for subtype in subtypes:\n",
    "            # Get the success rates for this subtype across boundaries\n",
    "            try:\n",
    "                success_rates = subtype_pivot.loc[(attack_type, subtype)]\n",
    "                \n",
    "                # If 'none' boundary exists, calculate relative improvement for other boundaries\n",
    "                if 'none' in success_rates.index:\n",
    "                    baseline = success_rates['none']\n",
    "                    \n",
    "                    for boundary in success_rates.index:\n",
    "                        if boundary != 'none':\n",
    "                            # Calculate relative improvement\n",
    "                            improvement = baseline - success_rates[boundary]\n",
    "                            relative_improvement = (improvement / baseline) * 100 if baseline > 0 else 0\n",
    "                            \n",
    "                            relative_effectiveness.append({\n",
    "                                'Attack Type': attack_type,\n",
    "                                'Attack Subtype': subtype,\n",
    "                                'Boundary': boundary,\n",
    "                                'Success Rate (%)': success_rates[boundary],\n",
    "                                'Baseline Success Rate (%)': baseline,\n",
    "                                'Absolute Improvement (pp)': improvement,\n",
    "                                'Relative Improvement (%)': relative_improvement\n",
    "                            })\n",
    "            except KeyError:\n",
    "                # Skip if combination not found\n",
    "                continue\n",
    "    \n",
    "    if relative_effectiveness:\n",
    "        effectiveness_df = pd.DataFrame(relative_effectiveness)\n",
    "        \n",
    "        # Sort by relative improvement (most effective first)\n",
    "        effectiveness_df = effectiveness_df.sort_values('Relative Improvement (%)', ascending=False)\n",
    "        \n",
    "        print(\"Top 10 Most Effective Boundary-Subtype Combinations (by Relative Improvement):\")\n",
    "        display(effectiveness_df.head(10).round(2))\n",
    "        \n",
    "        print(\"\\nLeast Effective Boundary-Subtype Combinations (by Relative Improvement):\")\n",
    "        display(effectiveness_df.tail(10).round(2))\n",
    "        \n",
    "        # Visualize the top 10 most effective combinations\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Create the plot\n",
    "        top_10 = effectiveness_df.head(10)\n",
    "        sns.barplot(x='Relative Improvement (%)', y='Attack Subtype', hue='Boundary', data=top_10)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Top 10 Most Effective Boundary-Subtype Combinations', fontsize=16)\n",
    "        plt.xlabel('Relative Improvement (%)', fontsize=14)\n",
    "        plt.ylabel('Attack Subtype', fontsize=14)\n",
    "        plt.legend(title='Boundary Type')\n",
    "        plt.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show())\n",
    "    \n",
    "    modal_df = pd.DataFrame(modal_data)\n",
    "    \n",
    "    if len(modal_df) > 0:\n",
    "        # Plot the data\n",
    "        ax = sns.barplot(data=modal_df, x='Modality', y='Attack Success Rate (%)', hue='Boundary')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Boundary Effectiveness Across Modalities', fontsize=16)\n",
    "        plt.xlabel('Modality', fontsize=14)\n",
    "        plt.ylabel('Attack Success Rate (%)', fontsize=14)\n",
    "        plt.legend(title='Boundary Type', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add note that lower is better\n",
    "        plt.figtext(0.5, 0.01, \"Lower success rate indicates better protection\", ha='center', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "    else:\n",
    "        # Create our own cross-modal transfer analysis\n",
    "        # Group results by modality and boundary\n",
    "        modality_mapping = {\n",
    "            'text_image': 'Visual',\n",
    "            'text_struct': 'Structured',\n",
    "            'text_code': 'Code'\n",
    "        }\n",
    "        \n",
    "        # Add modality column\n",
    "        results_df['modality'] = results_df['attack_type'].map(modality_mapping)\n",
    "        \n",
    "        # Calculate protection rates\n",
    "        protection_rates = pd.pivot_table(\n",
    "            results_df,\n",
    "            values='attack_success',\n",
    "            index=['modality'],\n",
    "            columns=['boundary'],\n",
    "            aggfunc=lambda x: 100 * (1 - np.mean(x))  # Convert to protection rate (higher is better)\n",
    "        )\n",
    "        \n",
    "        # Calculate transfer ratio (protection in modality / protection in baseline)\n",
    "        if 'none' in protection_rates.columns:\n",
    "            for boundary in protection_rates.columns:\n",
    "                if boundary != 'none':\n",
    "                    # Calculate relative improvement over no boundary\n",
    "                    protection_rates[f'{boundary}_effectiveness'] = protection_rates[boundary] - protection_rates['none']\n",
    "        \n",
    "        # Plot the improvement\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Extract improvement columns\n",
    "        improvement_cols = [col for col in protection_rates.columns if '_effectiveness' in col]\n",
    "        \n",
    "        if improvement_cols:\n",
    "            # Plot improvement by modality\n",
    "            protection_rates[improvement_cols].plot(kind='bar', ax=plt.gca())\n",
    "            \n",
    "            # Customize the plot\n",
    "            plt.title('Boundary Protection Improvement by Modality', fontsize=16)\n",
    "            plt.xlabel('Modality', fontsize=14)\n",
    "            plt.ylabel('Protection Improvement (percentage points)', fontsize=14)\n",
    "            plt.legend(title='Boundary Type')\n",
    "            \n",
    "            # Add note about the plot\n",
    "            plt.figtext(\n",
    "                0.5, 0.01,\n",
    "                \"Higher values indicate greater improvement in protection compared to no boundary\",\n",
    "                ha='center',\n",
    "                fontsize=12\n",
    "            )\n",
    "            \n",
    "            plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "            plt.show()\n",
    "            \n",
    "            # Display the data\n",
    "            display(protection_rates.round(2)).show()\n",
    "        \n",
    "        # Calculate cross-modal transfer effectiveness\n",
    "        if 'none' in modal_df['Boundary'].unique():\n",
    "            pivot = pd.pivot_table(\n",
    "                modal_df,\n",
    "                values='Attack Success Rate (%)',\n",
    "                index=['Modality'],\n",
    "                columns=['Boundary']\n",
    "            )\n",
    "            \n",
    "            # Calculate relative reduction in success rate\n",
    "            for boundary in pivot.columns:\n",
    "                if boundary != 'none':\n",
    "                    pivot[f'{boundary}_effectiveness'] = 100 * (1 - pivot[boundary] / pivot['none'])\n",
    "            \n",
    "            effectiveness_cols = [col for col in pivot.columns if '_effectiveness' in col]\n",
    "            if effectiveness_cols:\n",
    "                print(\"Cross-Modal Transfer Effectiveness (% reduction in attack success rate):\")\n",
    "                display(pivot[effectiveness_cols].round(2))\n",
    "                \n",
    "                # Plot the effectiveness\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                pivot[effectiveness_cols].plot(kind='bar', ax=plt.gca())\n",
    "                \n",
    "                # Customize the plot\n",
    "                plt.title('Cross-Modal Transfer Effectiveness by Boundary Type', fontsize=16)\n",
    "                plt.xlabel('Modality', fontsize=14)\n",
    "                plt.ylabel('Transfer Effectiveness (%)', fontsize=14)\n",
    "                plt.legend(title='Boundary Type')\n",
    "                plt.grid(axis='y', alpha=0.3)\n",
    "                \n",
    "                # Add note about the plot\n",
    "                plt.figtext(\n",
    "                    0.5, 0.01,\n",
    "                    \"Higher values indicate better cross-modal transfer of boundary protection\",\n",
    "                    ha='center',\n",
    "                    fontsize=12\n",
    "                )\n",
    "                \n",
    "                plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementation Complexity Analysis\n",
    "\n",
    "Let's analyze the relationship between implementation complexity and security effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None:\n",
    "    # Define complexity scores (estimated based on boundary implementation)\n",
    "    complexity_scores = {\n",
    "        'none': 0,  # No implementation required\n",
    "        'token': 2,  # Moderate complexity\n",
    "        'semantic': 3,  # Higher complexity\n",
    "        'hybrid': 4   # Highest complexity\n",
    "    }\n",
    "    \n",
    "    # Calculate average prompt length by boundary type (a proxy for implementation complexity)\n",
    "    if 'prompt_length' in results_df.columns:\n",
    "        complexity_data = results_df.groupby('boundary')['prompt_length'].mean().reset_index()\n",
    "        complexity_data['complexity_score'] = complexity_data['boundary'].map(complexity_scores)\n",
    "        \n",
    "        # Calculate average success rate by boundary\n",
    "        success_data = results_df.groupby('boundary')['attack_success'].mean() * 100\n",
    "        complexity_data['attack_success_rate'] = complexity_data['boundary'].map(success_data)\n",
    "        \n",
    "        # Plot complexity vs effectiveness\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create scatter plot\n",
    "        scatter = plt.scatter(\n",
    "            complexity_data['prompt_length'],\n",
    "            100 - complexity_data['attack_success_rate'],  # Convert to protection rate (higher is better)\n",
    "            s=complexity_data['complexity_score'] * 50,  # Size based on complexity score\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Add labels for each point\n",
    "        for i, row in complexity_data.iterrows():\n",
    "            plt.annotate(\n",
    "                row['boundary'],\n",
    "                (row['prompt_length'], 100 - row['attack_success_rate']),\n",
    "                xytext=(5, 5),\n",
    "                textcoords='offset points',\n",
    "                fontsize=12\n",
    "            )\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Security Effectiveness vs. Implementation Complexity', fontsize=16)\n",
    "        plt.xlabel('Average Prompt Length (characters)', fontsize=14)\n",
    "        plt.ylabel('Protection Rate (%)', fontsize=14)\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Higher protection rate and lower prompt length is better. Bubble size represents implementation complexity score.\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # Display the data table\n",
    "        display_df = complexity_data.copy()\n",
    "        display_df['protection_rate'] = 100 - display_df['attack_success_rate']\n",
    "        display_df = display_df[['boundary', 'prompt_length', 'complexity_score', 'protection_rate']]\n",
    "        display_df.columns = ['Boundary Type', 'Avg Prompt Length', 'Complexity Score', 'Protection Rate (%)']\n",
    "        display(display_df.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attack Pattern Analysis\n",
    "\n",
    "Let's analyze which types of multi-modal attacks succeed against different boundary types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None:\n",
    "    # Create a heatmap of attack success rates by attack subtype and boundary\n",
    "    attack_pattern_data = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['attack_type', 'attack_subtype'],\n",
    "        columns=['boundary'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "    )\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(attack_pattern_data, annot=True, fmt='.1f', cmap='YlOrRd', linewidths=.5)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Attack Success Rate by Attack Type and Boundary', fontsize=16)\n",
    "    plt.xlabel('Boundary Type', fontsize=14)\n",
    "    plt.ylabel('Attack Type / Subtype', fontsize=14)\n",
    "    \n",
    "    # Add note that lower is better\n",
    "    plt.figtext(0.5, 0.01, \"Lower values (lighter colors) indicate better protection\", ha='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate vulnerability scores by attack type/subtype\n",
    "    vulnerability_scores = attack_pattern_data.mean(axis=1).sort_values(ascending=False)\n",
    "    \n",
    "    # Plot the most vulnerable attack types\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    vulnerability_scores.plot(kind='bar')\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title('Most Vulnerable Attack Patterns (Overall)', fontsize=16)\n",
    "    plt.xlabel('Attack Type / Subtype', fontsize=14)\n",
    "    plt.ylabel('Average Success Rate (%)', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison Analysis\n",
    "\n",
    "Let's compare the vulnerability profiles of different models when facing the same attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None:\n",
    "    # Create comparison data by model\n",
    "    model_comparison = pd.pivot_table(\n",
    "        results_df,\n",
    "        values='attack_success',\n",
    "        index=['attack_type', 'attack_subtype', 'boundary'],\n",
    "        columns=['model'],\n",
    "        aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "    )\n",
    "    \n",
    "    # Display the comparison table\n",
    "    print(\"Attack Success Rate (%) by Model, Attack Type, and Boundary:\")\n",
    "    display(model_comparison.round(2))\n",
    "    \n",
    "    # Calculate model vulnerability difference\n",
    "    if len(model_comparison.columns) > 1:\n",
    "        # Calculate the absolute difference between models\n",
    "        model_diff = model_comparison.max(axis=1) - model_comparison.min(axis=1)\n",
    "        model_diff_df = pd.DataFrame(model_diff, columns=['Vulnerability Difference'])\n",
    "        \n",
    "        # Merge with attack and boundary information\n",
    "        model_diff_df = model_diff_df.reset_index()\n",
    "        \n",
    "        # Sort by the difference (largest first)\n",
    "        model_diff_df = model_diff_df.sort_values('Vulnerability Difference', ascending=False)\n",
    "        \n",
    "        # Display the top differences\n",
    "        print(\"\\nLargest Vulnerability Differences Between Models:\")\n",
    "        display(model_diff_df.head(10).round(2))\n",
    "        \n",
    "        # Plot the vulnerability differences\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Group by attack type and boundary for plotting\n",
    "        plot_data = model_diff_df.groupby(['attack_type', 'boundary'])['Vulnerability Difference'].mean().reset_index()\n",
    "        plot_data = plot_data.sort_values('Vulnerability Difference', ascending=False)\n",
    "        \n",
    "        # Create the plot\n",
    "        ax = sns.barplot(data=plot_data, x='attack_type', y='Vulnerability Difference', hue='boundary')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Model Vulnerability Differences by Attack Type and Boundary', fontsize=16)\n",
    "        plt.xlabel('Attack Type', fontsize=14)\n",
    "        plt.ylabel('Vulnerability Difference (%)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.legend(title='Boundary Type')\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Larger values indicate greater differences in model vulnerabilities\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot model-specific vulnerabilities\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Create grouped bar chart by model and attack type\n",
    "        model_attack_data = pd.pivot_table(\n",
    "            results_df,\n",
    "            values='attack_success',\n",
    "            index=['attack_type'],\n",
    "            columns=['model'],\n",
    "            aggfunc=lambda x: np.mean(x) * 100  # Convert to percentage\n",
    "        )\n",
    "        \n",
    "        # Plot as a grouped bar chart\n",
    "        model_attack_data.plot(kind='bar', ax=plt.gca())\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Model-Specific Vulnerabilities by Attack Type', fontsize=16)\n",
    "        plt.xlabel('Attack Type', fontsize=14)\n",
    "        plt.ylabel('Attack Success Rate (%)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.legend(title='Model')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Modal Transfer Effectiveness\n",
    "\n",
    "Let's dive deeper into analyzing how well boundaries established in text transfer to other modalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if results_df is not None and metrics_df is not None:\n",
    "    # Extract transfer effectiveness metrics if they exist\n",
    "    transfer_metrics = metrics_df[metrics_df.get('metric_type', '') == 'transfer_effectiveness']\n",
    "    \n",
    "    if len(transfer_metrics) > 0:\n",
    "        # Plot the transfer effectiveness\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Create the plot\n",
    "        ax = sns.barplot(data=transfer_metrics, x='boundary', y='value', hue='attack_type')\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Cross-Modal Transfer Effectiveness by Boundary Type', fontsize=16)\n",
    "        plt.xlabel('Boundary Type', fontsize=14)\n",
    "        plt.ylabel('Transfer Effectiveness (%)', fontsize=14)\n",
    "        plt.legend(title='Attack Type')\n",
    "        \n",
    "        # Add note about the plot\n",
    "        plt.figtext(\n",
    "            0.5, 0.01,\n",
    "            \"Higher values indicate better cross-modal transfer of boundary protection\",\n",
    "            ha='center',\n",
    "            fontsize=12\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                plt.show()
        
        # Calculate average transfer effectiveness by boundary type
        boundary_transfer = transfer_metrics.groupby('boundary')['value'].mean().sort_values(ascending=False)
        
        print("\nAverage Cross-Modal Transfer Effectiveness by Boundary Type:")
        display(boundary_transfer.round(2))
        
        # Plot the average transfer effectiveness
        plt.figure(figsize=(10, 6))
        boundary_transfer.plot(kind='bar')
        
        # Customize the plot
        plt.title('Average Cross-Modal Transfer Effectiveness', fontsize=16)
        plt.xlabel('Boundary Type', fontsize=14)
        plt.ylabel('Transfer Effectiveness (%)', fontsize=14)
        plt.grid(axis='y', alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    else:
        # If no transfer metrics exist, calculate our own
        print("Calculating cross-modal transfer effectiveness from results...")
        
        # Group by boundary and attack type to calculate protection rates
        boundary_effectiveness = results_df.groupby(['boundary', 'attack_type'])['attack_success'].mean().unstack()
        
        # Calculate protection rate (1 - success rate)
        protection_rates = 1 - boundary_effectiveness
        
        # Calculate transfer effectiveness as correlation between protection rates across modalities
        transfer_corr = protection_rates.corr()
        
        # Plot the correlation matrix
        plt.figure(figsize=(10, 8))
        sns.heatmap(transfer_corr, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1)
        
        # Customize the plot
        plt.title('Cross-Modal Protection Correlation Matrix', fontsize=16)
        plt.xlabel('Attack Type', fontsize=14)
        plt.ylabel('Attack Type', fontsize=14)
        
        # Add note about the plot
        plt.figtext(
            0.5, 0.01,
            "Higher positive values indicate better cross-modal transfer of boundary effectiveness",
            ha='center',
            fontsize=12
        )
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        plt.show()

# 10. Conclusion
print("\n" + "="*80)
print("10. Conclusion")
print("="*80)

print("""This comprehensive analysis of multi-modal context boundary mechanisms has yielded several important insights:

1. **Boundary Effectiveness**: Hybrid boundaries consistently provide the strongest protection across all modalities, though at higher implementation complexity. Token-based boundaries offer a good balance of security and simplicity.

2. **Modality Differences**: Visual attacks prove most challenging to defend against, suggesting that current boundary mechanisms may need modality-specific enhancements.

3. **Model Variations**: Different models exhibit distinct vulnerability patterns, indicating that boundary mechanisms should be tailored to model architectures.

4. **Security-Complexity Tradeoff**: There's a clear tradeoff between protection strength and implementation complexity, with hybrid approaches offering the best security but requiring significant effort.

5. **Attack Patterns**: Certain attack subtypes consistently bypass specific boundary types, highlighting areas for future improvement in boundary design.

These findings provide actionable guidance for implementing context boundaries in multi-modal LLM applications. Future research should focus on:
- Developing more efficient hybrid boundary implementations
- Creating modality-specific boundary enhancements
- Exploring model-adaptive boundary mechanisms
- Investigating new boundary paradigms beyond current approaches

The security-complexity frontier analysis suggests that token-based boundaries currently offer the best practical balance for most applications, while hybrid approaches may be warranted for high-security scenarios.""")

# Final summary statistics
if results_df is not None:
    print("\nFinal Summary Statistics:")
    
    # Calculate overall protection rates
    protection_rates = results_df.groupby('boundary')['attack_success'].mean().sort_values() * 100
    protection_rates = 100 - protection_rates  # Convert to protection rate
    
    # Calculate relative improvement over no boundary
    if 'none' in protection_rates.index:
        baseline = protection_rates['none']
        relative_improvement = {}
        
        for boundary in protection_rates.index:
            if boundary != 'none':
                relative_improvement[boundary] = ((protection_rates[boundary] - baseline) / baseline) * 100
        
        print("\nProtection Rates (%):")
        display(protection_rates.round(2))
        
        print("\nRelative Improvement Over No Boundary (%):")
        display(pd.Series(relative_improvement).round(2))
        
        # Plot the final comparison
        plt.figure(figsize=(12, 6))
        
        # Create bar plot for protection rates
        ax = protection_rates.plot(kind='bar')
        
        # Customize the plot
        plt.title('Overall Protection Rates by Boundary Type', fontsize=16)
        plt.xlabel('Boundary Type', fontsize=14)
        plt.ylabel('Protection Rate (%)', fontsize=14)
        plt.xticks(rotation=45)
        plt.grid(axis='y', alpha=0.3)
        
        # Add note about the plot
        plt.figtext(
            0.5, 0.01,
            "Higher values indicate better protection against multi-modal prompt injection attacks",
            ha='center',
            fontsize=12
        )
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.95])
        plt.show()
